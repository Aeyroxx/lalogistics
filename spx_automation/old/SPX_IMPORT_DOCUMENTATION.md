# SPX Import Feature Documentation

## Overview
The SPX Import feature allows administrators to bulk import audit data generated by the SPX automation script directly into the L&A Logistics audit system.

## Access
- **URL**: `/audit/import/spx`
- **Access Level**: Admin only
- **Navigation**: Available in audit list page, audit form page, and sidebar menu

## How It Works

### 1. File Upload
- Accepts JSON files up to 10MB
- Validates file format and structure
- Provides real-time feedback

### 2. Data Processing
- Only processes tasks with "Done" status
- Creates separate audit entries for each sender ID
- Automatically calculates earnings using SPX commercial terms
- Checks for duplicates to avoid double entries

### 3. Import Results
- Shows detailed results with counts and errors
- Lists skipped duplicates and processing errors
- Provides next steps for data management

## JSON File Format

The expected JSON format matches the output from the SPX automation script:

```json
[
  {
    "receive_task_id": "DRT2025080601VEC",
    "complete_time": "2025-08-06 14:30:00",
    "status": "Done",
    "sender_data": {
      "1257601721": 25,
      "1234567890": 18
    },
    "total_quantity": 43,
    "sender_count": 2,
    "processed_at": "2025-08-06T14:30:00.000Z"
  }
]
```

### Required Fields:
- **receive_task_id**: SPX task identifier
- **status**: Task status (only "Done" tasks are imported)
- **sender_data**: Object with sender IDs as keys and tracking counts as values

### Optional Fields:
- **complete_time**: Task completion time (defaults to current time)
- **total_quantity**: Total parcels (calculated from sender_data)
- **sender_count**: Number of senders (calculated from sender_data)
- **processed_at**: Processing timestamp

## Data Mapping

| SPX Automation Field | Audit Database Field | Notes |
|---------------------|----------------------|-------|
| receive_task_id | taskId | Direct mapping |
| sender_data key | sellerId | Each sender becomes separate entry |
| sender_data key | shopId | Uses sender ID as shop ID |
| sender_data value | numberOfParcels | Tracking count becomes parcel count |
| complete_time | date | Parsed to Date object |
| status | - | Only "Done" status imported |

## Default Values for Imported Entries

- **handedOverWithinSLA**: `true` (can be edited later)
- **amount**: `0` (calculated by pre-save hook)
- **penalties**: `0`
- **notes**: "Imported from SPX automation on [timestamp]"
- **createdBy**: Current admin user

## Business Rules Applied

### SPX Commercial Terms (2025)
- **Base Rate**: â‚±0.50 for first 100 parcels per Shop ID
- **Bonus Rate**: Same as base rate if SLA compliant
- **Order Cap**: Only first 100 parcels per Shop ID per day qualify
- **Penalties**: Can be added manually after import

### Duplicate Prevention
- Checks for existing entries with same:
  - Task ID
  - Sender ID
  - Date (same day)
- Skips duplicates automatically

## Import Process

1. **File Validation**
   - Checks file type (JSON only)
   - Validates file size (max 10MB)
   - Parses JSON structure

2. **Data Processing**
   - Filters tasks by "Done" status
   - Processes each sender in each task
   - Creates individual audit entries
   - Applies business rules and calculations

3. **Results Reporting**
   - Counts imported, skipped, and error entries
   - Lists specific errors and duplicates
   - Provides navigation to view imported data

## Error Handling

### Common Errors:
- **Invalid JSON**: File cannot be parsed as valid JSON
- **Missing Fields**: Required fields are missing from task objects
- **Database Errors**: Issues creating audit entries
- **Duplicate Detection**: Entry already exists in database

### Error Recovery:
- Partial imports are allowed (some entries succeed, others fail)
- Detailed error messages help identify issues
- Temp files are cleaned up automatically

## Best Practices

### Before Import:
1. Verify JSON file format matches expected structure
2. Check for existing data to understand duplicate behavior
3. Ensure SPX automation generated "Done" status tasks

### After Import:
1. Review imported entries in audit list
2. Verify shop IDs are correct (update if needed)
3. Check SLA compliance status
4. Add any applicable penalties
5. Generate reports to verify earnings calculations

### File Management:
- Keep backup copies of import files
- Use descriptive filenames with dates
- Test with small files first
- Monitor import results for accuracy

## Troubleshooting

### File Upload Issues:
- Check file size (max 10MB)
- Ensure file extension is .json
- Verify file is not corrupted

### Import Errors:
- Check JSON format with validator
- Ensure all required fields are present
- Verify sender IDs are valid numbers/strings

### Performance:
- Large files may take longer to process
- Break large imports into smaller files if needed
- Monitor server resources during import

## Integration with SPX Automation

This import feature is designed to work with the SPX automation scripts in the `/spx_automation/` folder:

1. Run SPX automation to generate JSON output
2. Locate the generated JSON file in `/spx_automation/output/`
3. Use the web interface to import the data
4. Review and manage imported audit entries

## Security Considerations

- Admin-only access prevents unauthorized imports
- File type validation prevents malicious uploads
- Temp files are cleaned up automatically
- Input validation prevents injection attacks
- Duplicate checking prevents data corruption

## Future Enhancements

Potential improvements for the import feature:

1. **CSV Import**: Support for CSV format files
2. **Excel Import**: Support for Excel (.xlsx) files
3. **Bulk Edit**: Mass edit capabilities for imported data
4. **Schedule Import**: Automated import from folder
5. **Data Validation**: Enhanced validation rules
6. **Import History**: Track import operations and results
